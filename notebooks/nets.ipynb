{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZfCSOU7rI7wM",
        "d23f7753",
        "jr4PNulULpFz",
        "sA85-cj2P-dq",
        "5c5bC97_QNeQ",
        "0KVFgOdNJGZe",
        "40806855",
        "45249024"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtcaxBqy+J0ZxscyPbd4gc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mateus929/Facial-Expression-Recognition-Challenge/blob/main/notebooks/nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ZfCSOU7rI7wM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a3f8dfb"
      },
      "source": [
        "## Data Preparation: Mounting Google Drive\n",
        "\n",
        "As a first step, this notebook demonstrates how to mount your Google Drive to access files stored there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "447e63d5",
        "outputId": "ab4031d3-f0eb-40ea-edb3-5f8de70116c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23f7753"
      },
      "source": [
        "## Data Loading and Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05810750"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "e6e6db1c",
        "outputId": "7e5b8ca9-edfe-45ba-cd63-0f16f132c6e2"
      },
      "source": [
        "# Note: Make sure the file path is correct and the file exists in your Google Drive.\n",
        "# The path should be '/content/drive/MyDrive/Colab Notebooks/Facial Expression Recognition Challenge/data/your_data_file.csv'\n",
        "# Replace 'your_data_file.csv' with the actual name of your training data file.\n",
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Facial Expression Recognition Challenge/data/train.csv')\n",
        "    print(\"Training data loaded successfully!\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The training data file was not found. Please check the file path and name.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the data: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data loaded successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   emotion                                             pixels\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91c85cac-2f4e-4c30-bf2e-ae715084c4e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91c85cac-2f4e-4c30-bf2e-ae715084c4e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91c85cac-2f4e-4c30-bf2e-ae715084c4e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91c85cac-2f4e-4c30-bf2e-ae715084c4e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2d45150d-cbbc-48f0-a8dd-3c578ac8eb51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d45150d-cbbc-48f0-a8dd-3c578ac8eb51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2d45150d-cbbc-48f0-a8dd-3c578ac8eb51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"An error occurred while loading the data: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"151 150 147 155 148 133 111 140 170 174 182 154 153 164 173 178 185 185 189 187 186 193 194 185 183 186 180 173 166 161 147 133 172 151 114 161 161 146 131 104 95 132 163 123 119 129 140 120 151 149 149 153 137 115 129 166 170 181 164 143 157 156 169 179 185 183 186 186 184 190 191 184 186 190 183 175 168 160 147 136 135 167 136 108 153 167 149 137 111 90 134 162 121 122 141 137 151 151 156 143 116 124 159 164 174 169 135 144 155 153 164 170 176 178 177 178 187 185 181 182 183 181 178 170 164 158 148 144 130 136 173 130 97 137 167 157 138 113 90 138 168 109 123 146 151 152 155 127 113 159 167 170 171 142 131 140 154 162 168 169 169 164 168 173 176 179 178 176 173 172 170 161 154 152 146 145 137 124 130 171 124 102 133 164 152 138 110 86 154 149 100 139 153 151 136 113 142 159 161 174 150 127 136 140 154 164 163 167 173 172 171 170 167 168 172 167 162 161 160 163 163 154 145 146 140 133 122 135 167 127 101 126 164 147 132 95 91 166 115 113 158 143 121 134 153 153 164 162 131 130 136 146 155 158 155 157 163 163 158 159 159 161 165 156 153 156 159 163 163 150 149 150 146 140 137 122 147 154 116 97 133 164 142 123 77 117 147 95 149 127 129 153 142 165 171 136 116 129 130 139 140 149 153 147 146 150 150 155 151 155 156 153 152 157 165 165 160 150 156 156 148 141 135 135 132 147 141 110 97 143 165 142 101 66 151 117 136 125 148 139 153 173 159 118 116 119 123 131 134 145 145 137 142 151 157 159 153 154 153 150 159 170 171 167 160 160 159 158 152 141 145 144 140 119 144 133 106 101 151 148 130 70 119 148 129 143 146 134 165 165 134 121 123 121 125 129 136 150 159 163 165 161 157 155 147 150 148 135 156 171 169 171 166 165 165 158 153 146 147 150 137 122 112 144 122 94 111 158 143 91 74 155 134 147 131 154 167 153 107 125 129 134 137 134 136 154 168 174 171 168 163 156 151 150 146 146 166 171 173 176 177 191 187 175 180 179 174 165 142 134 108 111 137 108 86 143 156 116 64 133 143 129 138 162 167 132 117 127 128 140 147 145 155 159 165 170 172 166 160 154 156 160 156 156 158 153 170 188 198 208 203 209 219 217 200 174 171 147 128 92 129 131 88 103 159 135 75 111 133 126 160 156 159 117 132 129 131 144 160 165 162 166 170 165 160 160 159 153 149 150 151 148 120 132 189 183 180 177 187 201 194 186 181 170 167 146 118 117 100 139 112 74 139 145 85 91 120 151 156 164 129 111 135 140 139 142 158 163 172 190 195 189 168 156 149 143 137 140 140 132 114 142 150 129 133 125 138 140 132 114 124 131 118 143 125 126 82 97 141 72 113 152 93 77 134 157 149 166 95 124 136 142 156 165 179 189 198 198 186 186 188 157 126 124 118 129 128 115 95 100 90 84 81 66 72 80 77 63 59 65 70 67 86 105 82 95 138 89 94 153 106 74 153 148 165 134 80 134 137 149 173 187 193 201 185 169 141 128 150 139 113 119 123 128 114 91 71 60 51 69 78 80 80 79 76 76 65 65 85 103 46 73 142 85 114 114 75 145 121 70 150 141 168 76 91 130 144 179 197 210 190 164 146 128 121 90 92 90 90 114 104 109 110 81 52 53 87 96 94 99 96 88 95 108 116 110 97 120 98 64 120 77 105 130 67 131 128 67 137 150 136 46 106 126 164 164 151 150 131 115 103 88 90 91 92 78 56 49 65 90 115 66 29 91 99 104 107 88 94 105 111 118 113 116 103 103 120 47 83 110 120 134 67 116 136 74 133 163 82 51 113 115 104 112 144 162 138 104 96 93 95 90 91 99 103 55 29 46 45 16 40 104 95 101 92 93 96 80 69 82 99 98 108 116 128 70 102 117 127 140 79 105 139 82 140 149 23 43 103 50 78 179 185 147 111 113 117 106 91 95 100 91 96 92 19 6 19 8 35 88 64 66 60 72 68 34 35 70 85 101 118 130 143 82 114 125 130 149 93 104 139 83 148 130 67 86 94 42 142 173 151 128 124 106 96 103 90 89 100 97 95 103 28 48 127 126 38 87 81 68 64 70 74 51 68 92 112 139 149 152 158 100 134 128 133 159 105 95 139 86 153 113 62 126 130 62 135 136 127 122 93 67 54 44 42 43 60 76 86 104 41 115 197 211 112 67 118 109 107 93 84 83 101 108 129 150 158 156 143 105 140 129 131 166 115 85 137 87 156 99 21 89 104 46 117 135 113 78 52 89 94 46 24 45 54 65 95 92 49 161 213 212 188 85 97 133 130 124 121 122 136 147 143 154 151 173 124 115 147 129 124 164 136 95 126 85 159 94 36 97 117 78 93 130 90 73 77 94 86 61 60 72 69 91 113 80 76 188 214 213 200 143 66 119 138 150 151 151 159 163 156 154 162 140 107 136 148 135 115 158 150 116 111 87 161 101 50 109 111 98 69 99 97 109 111 114 106 95 96 99 101 109 122 70 111 193 214 217 200 183 115 78 124 157 167 170 172 166 161 147 127 118 134 138 141 141 119 147 155 131 98 96 163 103 72 120 112 115 80 100 117 100 105 127 138 133 132 140 137 121 103 64 153 200 215 218 205 183 169 127 77 92 111 122 126 128 128 129 135 145 141 138 133 138 127 139 169 127 83 93 161 106 87 122 106 117 114 88 124 116 108 135 150 151 156 163 162 121 66 110 177 201 212 214 200 181 162 155 117 97 103 109 115 119 131 141 147 149 141 146 140 128 130 140 170 101 87 89 163 109 105 123 103 112 133 113 95 132 139 160 167 169 158 149 118 72 89 133 169 189 197 204 194 180 172 166 138 114 112 114 120 119 125 134 140 150 145 142 145 142 144 152 164 116 95 84 159 113 111 124 101 112 136 134 115 107 118 131 138 129 108 93 75 88 112 136 170 183 181 178 181 177 177 180 175 130 110 119 125 130 131 135 138 142 146 136 130 146 142 157 169 135 91 100 150 115 114 138 107 114 133 125 124 133 137 128 119 106 102 98 93 96 141 160 147 149 150 145 153 161 147 146 175 162 114 112 121 127 128 131 129 134 142 136 124 139 141 157 175 138 106 149 145 119 119 150 109 115 136 129 126 131 137 130 114 106 108 109 99 115 156 138 116 134 139 130 140 119 53 45 103 139 131 101 98 117 126 130 123 124 133 137 131 130 143 160 177 148 158 182 146 122 117 161 118 116 131 134 130 130 124 121 118 117 119 112 92 107 134 74 29 73 122 129 126 78 33 42 65 107 123 103 97 96 113 121 119 121 124 131 130 128 157 176 179 185 187 181 158 124 111 169 131 116 123 129 130 129 129 128 125 124 114 86 89 104 91 46 31 35 74 113 107 93 79 79 94 121 131 126 119 92 100 114 114 117 115 120 125 130 164 179 188 192 182 184 182 140 106 170 147 120 121 129 130 127 128 129 128 123 98 62 98 116 113 94 90 85 81 80 104 116 126 141 136 148 148 129 122 101 95 107 107 117 123 125 130 139 165 179 184 192 184 183 191 167 119 173 158 136 118 130 131 125 123 123 125 114 81 71 131 147 148 138 133 117 101 88 118 131 143 163 167 165 164 146 132 122 107 95 104 115 126 136 137 146 168 180 179 195 187 183 188 186 141 158 165 147 116 131 130 124 118 117 119 102 70 101 140 154 153 142 134 125 118 117 118 116 120 137 149 163 172 158 144 137 138 117 112 123 129 139 146 157 167 175 178 196 190 184 190 188 167 155 174 161 134 119 114 121 118 113 109 89 93 134 140 161 170 145 126 108 121 117 108 117 136 146 142 138 150 149 147 135 142 122 115 142 149 144 144 162 168 171 176 192 187 182 192 183 185 175 174 145 87 65 63 84 112 114 98 92 109 140 155 151 147 123 103 111 112 116 108 111 127 130 117 115 124 129 138 124 118 120 114 135 144 141 144 154 168 170 174 187 182 179 187 184 184 187 132 28 6 24 36 39 69 111 99 84 109 134 133 108 97 84 75 78 74 81 80 62 48 32 27 36 42 56 88 87 86 123 130 138 138 134 141 151 170 167 173 189 184 181 187 186 191 192 63 26 18 3 16 22 23 85 106 98 110 112 89 47 35 41 20 18 21 13 9 7 3 2 4 4 3 4 30 40 49 112 129 142 143 139 144 151 171 174 177 188 186 181 189 189 170 124 47 33 28 8 4 12 11 48 111 113 100 85 50 19 4 5 3 10 14 12 15 26 31 35 38 37 40 62 84 73 61 124 143 138 130 140 139 152 157 170 179 186 186 181 179 115 39 26 14 6 10 3 1 5 2 48 124 117 106 71 34 42 32 17 17 24 35 41 49 63 67 70 72 88 106 118 107 97 75 95 139 138 125 130 131 150 160 173 183 188 186 184 114 54 84 157 71 0 6 5 4 3 0 75 122 109 103 69 53 67 68 59 55 54 59 65 74 88 97 104 109 119 129 128 127 130 98 96 136 156 130 117 128 148 165 176 190 191 186 183 74 64 167 201 164 43 1 0 0 3 46 114 118 110 110 67 66 97 83 86 87 98 93 98 102 112 119 119 125 126 130 128 127 135 134 112 123 150 136 118 126 146 158 179 196 188 185 185 142 50 136 182 194 173 83 58 60 100 130 121 113 120 116 80 77 95 103 111 116 124 116 120 117 119 108 123 129 144 160 143 129 130 127 132 123 149 132 117 125 142 151 188 194 187 184 185 197 128 84 169 177 199 178 162 147 154 146 124 107 129 120 96 88 99 131 131 145 131 137 148 131 133 128 124 118 142 167 159 130 136 134 127 128 143 133 118 139 140 144 192 196 187 184 184 188 188 121 86 175 189 192 157 148 144 149 126 113 123 127 106 96 107 145 143 144 131 147 150 143 147 134 126 131 151 170 162 148 116 139 122 124 141 127 112 128 116 113 159 201 185 185 186 188 187 196 129 85 171 194 171 142 144 144 128 119 116 121 116 100 108 136 146 128 135 151 146 152 150 158 143 133 143 159 153 152 128 137 133 125 127 102 108 109 105 102 106 197 186 182 187 186 184 185 197 124 84 174 185 150 129 143 135 115 102 111 124 112 109 132 146 135 149 148 143 163 156 159 150 139 128 116 125 133 109 130 147 130 121 105 108 95 108 102 67 171 193 183 184\",\n          \"4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84 115 127 137 142 151 156 155 149 153 152 157 160 162 159 145 121 83 58 48 38 21 17 7 5 25 27 24 25 1 0 0 0 0 0 0 0 0 0 0 6 18 26 37 50 62 83 115 134 138 144 147 150 162 163 164 161 165 169 171 176 175 177 169 147 110 79 64 42 23 13 9 2 16 26 23 26 0 0 0 0 0 0 0 0 0 1 6 18 29 49 73 93 116 129 138 143 148 153 158 158 162 168 170 169 170 176 181 185 186 183 180 167 143 109 81 54 29 11 8 3 10 27 26 26 0 0 0 0 0 0 0 0 0 8 32 55 74 94 108 121 127 132 138 145 154 159 160 162 166 170 174 173 177 181 183 183 186 188 188 180 164 138 113 69 36 14 4 3 11 27 29 28 0 0 0 0 0 0 0 0 11 40 71 87 95 105 114 122 126 136 144 148 155 163 163 166 171 172 172 173 177 182 184 186 190 191 191 186 175 162 146 95 41 21 5 2 13 30 32 30 0 0 0 0 0 0 0 6 30 56 79 93 98 108 116 124 129 137 145 154 158 169 174 173 175 173 176 178 182 185 185 188 192 194 195 192 185 184 174 129 65 23 11 2 15 34 33 32 0 0 1 0 0 0 1 14 39 60 80 95 104 112 122 129 134 140 150 158 164 173 180 181 183 179 183 185 185 188 190 192 195 197 198 195 192 192 180 147 84 33 13 3 17 35 33 32 0 0 1 0 0 0 2 19 41 57 78 95 106 120 132 136 138 146 158 163 171 177 182 187 189 185 189 190 190 193 194 196 201 198 198 199 196 197 180 147 90 34 10 3 21 38 34 33 0 0 0 0 0 1 6 22 38 54 81 101 113 124 135 143 146 152 166 173 180 186 188 191 190 189 192 194 197 197 200 201 204 200 200 200 200 200 186 151 95 31 7 2 20 42 38 35 0 0 0 0 1 4 11 28 39 54 84 109 124 131 138 146 153 159 174 181 183 187 188 195 198 201 199 202 205 205 206 206 205 201 200 198 201 203 191 160 112 35 6 3 10 39 39 36 0 0 0 0 2 5 19 36 37 54 88 109 121 135 149 158 163 171 179 181 183 187 192 190 198 207 208 206 209 211 207 210 208 206 201 198 205 207 194 163 130 49 2 3 7 31 40 37 0 0 0 0 2 9 25 34 34 56 89 101 111 127 139 147 149 158 159 167 175 178 185 186 199 209 206 205 197 193 187 191 190 185 186 182 185 201 199 166 146 68 5 4 8 23 41 39 0 0 0 0 2 16 26 30 32 54 79 95 107 112 111 102 104 105 112 108 131 159 176 182 197 206 201 190 171 154 142 129 125 128 133 153 168 179 190 166 151 82 7 3 4 19 41 39 0 0 0 0 4 20 26 26 30 54 86 110 119 120 115 94 78 80 88 96 97 131 167 177 192 208 201 180 149 127 109 94 91 98 116 137 160 175 179 154 143 90 8 3 2 15 41 40 0 0 0 0 7 23 20 20 37 76 105 117 116 90 62 46 39 45 71 104 101 110 151 176 191 209 204 186 151 126 106 85 69 68 85 115 138 156 176 169 140 92 9 4 5 15 41 42 6 0 0 0 8 23 13 16 40 81 100 85 41 11 7 14 28 33 29 69 93 91 136 165 189 210 209 193 139 102 78 50 33 28 24 26 71 122 147 174 151 92 14 2 0 13 40 41 41 5 0 0 8 16 5 7 34 41 31 8 0 2 7 21 31 46 59 36 62 72 116 156 189 210 212 180 101 77 50 21 17 23 32 36 22 34 104 159 143 93 14 17 73 55 38 43 41 12 0 0 11 23 4 1 6 0 0 0 3 20 32 35 48 49 64 59 33 51 98 151 188 210 207 162 93 73 32 35 35 29 35 40 59 18 27 97 86 96 21 95 152 100 42 42 27 9 0 0 14 22 4 5 6 2 3 22 68 95 49 69 143 174 90 73 34 39 84 143 187 217 212 164 122 68 120 140 51 55 132 133 62 23 11 21 58 104 35 121 139 106 45 41 30 6 0 3 19 18 2 7 18 9 4 51 138 114 96 94 144 231 167 50 37 45 72 133 187 220 215 178 115 128 241 180 90 85 141 193 129 43 9 27 60 104 40 90 155 118 41 42 27 5 0 8 22 18 5 28 63 69 40 7 47 91 84 95 118 99 74 65 43 48 70 126 189 222 219 188 113 100 124 142 113 96 110 123 66 13 44 76 71 108 47 70 160 103 36 43 27 8 2 13 23 32 54 98 121 130 117 76 50 54 70 67 74 75 83 73 47 53 74 127 191 222 222 198 150 94 65 75 77 67 61 43 53 91 145 174 160 133 58 63 162 81 36 44 24 7 8 14 21 42 72 105 133 137 140 137 132 129 125 123 130 127 115 90 61 61 80 135 199 230 225 211 195 177 171 154 142 143 147 155 172 194 206 207 199 165 68 122 143 51 41 44 25 13 16 13 21 39 62 91 126 139 146 149 150 150 146 142 137 126 115 87 67 65 80 138 203 233 228 218 212 210 205 193 190 196 199 205 209 211 210 204 198 163 55 138 111 37 45 44 20 23 27 10 17 35 57 84 117 137 149 158 161 159 154 148 139 134 116 85 68 65 82 141 199 229 230 223 217 216 212 206 203 203 201 203 206 208 211 207 192 148 53 121 94 36 47 45 25 18 40 14 14 31 51 80 110 129 148 161 165 165 157 151 145 136 118 87 64 61 80 136 194 226 229 222 217 219 216 213 210 207 205 208 207 210 214 204 183 138 72 90 69 40 47 45 41 12 30 27 14 26 42 72 103 125 142 157 165 165 159 155 146 132 110 76 52 52 84 132 189 221 224 221 212 217 220 216 211 207 206 206 208 212 209 194 171 134 108 79 43 45 46 43 43 45 19 37 18 24 34 61 93 115 133 152 162 165 161 151 146 130 105 65 38 53 98 140 183 214 224 219 207 212 218 218 216 209 205 206 206 207 199 181 156 123 133 101 45 49 44 42 64 90 55 38 25 25 30 48 78 104 122 142 159 161 157 151 141 128 98 48 35 64 109 154 193 214 233 228 202 207 217 218 216 210 207 206 202 200 191 168 141 147 154 100 47 63 45 41 102 98 77 44 29 28 31 42 64 93 113 131 149 156 152 148 141 124 66 43 51 79 132 176 203 223 234 229 220 208 212 217 213 211 208 204 197 187 176 148 161 201 173 98 41 56 47 41 112 97 74 53 29 32 32 41 56 80 103 124 141 148 148 150 148 109 37 61 68 83 119 169 187 202 207 199 220 213 204 212 215 211 208 203 187 172 158 140 176 198 188 114 39 48 45 40 77 96 92 65 21 31 34 40 52 73 95 113 131 139 143 148 154 128 41 78 97 44 71 129 156 170 148 116 167 201 199 207 211 209 208 200 182 167 152 145 182 194 193 90 36 46 44 41 22 76 88 42 3 28 36 40 51 71 90 108 121 129 137 142 153 152 101 79 114 46 38 99 138 170 142 141 163 202 202 202 204 206 205 191 178 171 157 147 175 165 124 48 41 43 44 42 24 10 9 18 0 19 39 42 50 68 90 107 114 122 128 138 144 138 129 117 92 71 98 122 146 190 195 192 207 208 208 203 201 202 200 188 178 172 166 118 75 76 61 42 44 42 44 42 56 0 0 21 2 10 38 43 47 59 82 101 112 121 123 132 129 122 123 125 112 99 135 167 165 191 211 213 207 206 211 210 202 200 196 189 183 174 168 97 33 44 101 57 38 41 44 44 96 0 1 40 14 2 31 40 45 54 71 92 109 115 117 121 117 119 130 127 117 117 148 169 161 184 199 205 203 205 212 209 203 198 194 188 183 174 167 82 44 35 150 109 28 43 42 43 103 0 0 76 28 0 24 39 44 51 60 79 101 103 109 119 112 118 126 128 123 126 151 183 151 163 201 203 203 206 209 207 201 198 192 187 181 174 158 64 47 35 146 112 27 43 40 39 99 0 0 77 16 0 13 35 42 47 52 68 88 92 103 111 111 113 112 117 119 123 142 181 163 165 192 204 216 217 207 204 200 195 189 183 177 168 167 78 47 32 154 128 29 47 41 41 62 0 7 33 1 1 3 26 39 45 48 58 74 84 96 105 109 98 100 105 107 107 101 108 125 130 130 140 157 189 208 195 190 186 184 177 173 165 165 100 38 42 91 73 43 44 40 40 30 20 20 14 0 1 0 15 34 42 45 51 65 74 90 103 82 64 73 82 88 82 81 90 90 100 98 94 94 94 126 145 161 186 180 173 170 164 86 63 41 51 58 42 43 42 40 37 0 19 17 0 1 1 0 8 28 37 42 49 60 68 89 98 70 49 47 72 80 67 62 74 87 94 97 123 124 110 93 92 127 172 176 168 171 139 38 50 59 58 47 41 41 41 38 37 0 0 0 0 0 1 0 8 21 31 39 44 54 69 81 99 87 65 55 71 85 85 102 126 139 146 169 183 182 169 164 160 150 160 168 163 166 94 33 40 48 43 38 39 44 41 37 36 0 0 0 0 0 0 0 7 19 22 34 39 48 62 73 84 81 76 71 69 74 89 105 129 137 150 164 156 151 157 168 176 161 156 163 161 141 54 40 36 34 39 36 38 43 40 36 35 0 0 0 0 0 0 0 5 20 17 26 37 44 53 63 69 78 88 92 88 91 94 98 103 109 116 129 147 162 171 173 171 159 155 154 158 99 36 44 36 34 37 34 37 39 37 36 34 0 0 0 0 0 0 0 4 18 17 16 32 41 51 55 60 69 82 94 100 108 117 124 131 120 119 129 148 165 170 168 162 162 155 151 126 40 40 40 31 33 34 34 36 36 34 34 33 0 0 0 0 0 0 0 2 17 18 14 20 36 46 55 55 63 77 86 98 111 121 126 133 136 136 138 152 166 169 164 165 169 156 140 46 0 24 36 32 32 34 32 33 35 34 32 30 0 0 0 0 0 0 0 2 18 21 16 12 22 36 49 54 59 72 88 100 110 123 125 135 144 160 166 166 176 177 173 172 167 148 102 9 0 1 25 35 33 33 30 29 35 33 31 30 0 0 0 0 0 0 0 0 18 27 19 13 11 22 37 48 55 67 88 95 112 118 123 141 157 174 181 185 184 179 176 171 155 128 105 10 0 0 12 34 31 31 31 27 31 30 29 30\",\n          \"231 212 156 164 174 138 161 173 182 200 106 38 39 74 138 161 164 179 190 201 210 216 220 224 222 218 216 213 217 220 220 218 217 212 174 160 162 160 139 135 137 131 94 56 36 44 27 16 229 175 148 173 154 151 171 172 183 101 23 25 67 127 164 170 171 182 199 212 219 220 224 226 226 226 226 226 227 227 228 225 221 217 202 174 158 155 145 126 126 129 99 70 37 27 35 27 214 156 157 168 153 172 168 175 100 16 8 47 117 169 175 175 183 194 204 214 218 223 225 227 228 226 229 231 232 232 229 227 225 224 217 198 174 154 134 110 97 115 96 69 52 28 22 28 202 153 166 156 164 166 170 116 26 2 21 90 165 180 180 181 192 206 210 213 216 220 224 224 226 224 228 227 227 228 231 229 225 228 226 218 196 168 148 111 80 89 97 56 50 38 26 23 190 163 167 156 168 172 136 36 0 24 69 146 180 179 183 196 204 211 214 215 214 217 218 217 220 223 220 220 222 224 227 229 228 228 228 227 216 187 156 125 92 62 83 61 44 46 31 31 181 173 156 167 176 159 61 0 8 62 121 175 185 188 197 210 215 222 225 221 216 214 214 214 213 214 214 214 216 218 218 220 220 225 226 220 216 205 175 133 98 68 61 70 47 41 36 36 183 169 159 174 181 97 6 1 27 98 158 180 192 205 212 221 222 224 229 227 223 217 215 214 211 211 211 209 212 213 212 210 210 215 214 215 212 208 191 140 100 70 57 73 55 37 35 33 183 160 171 185 138 21 0 0 48 140 179 191 210 224 229 231 228 226 231 231 230 222 218 214 212 208 209 210 209 207 208 206 207 209 208 206 208 203 195 166 106 66 55 65 51 53 26 36 172 164 175 174 58 0 1 0 85 172 184 210 237 243 244 237 235 229 225 232 236 226 218 216 213 212 209 207 211 209 209 208 209 208 206 205 205 200 192 178 121 65 50 54 37 42 55 35 171 166 178 124 9 2 0 21 138 184 189 203 214 210 223 241 240 231 218 225 231 226 226 220 217 217 218 214 214 216 219 215 215 216 210 206 201 195 192 181 148 79 45 45 46 31 42 66 171 168 176 52 0 4 0 73 175 186 201 198 191 167 146 181 223 235 220 219 223 219 223 222 222 222 221 222 219 223 224 223 225 223 215 209 203 197 191 183 170 104 45 38 53 40 26 50 166 179 138 45 13 5 23 142 185 175 178 166 165 151 108 103 131 192 224 220 212 217 216 213 224 222 222 224 222 226 226 227 225 220 212 209 205 200 194 188 179 132 53 22 48 49 31 29 175 177 104 59 37 15 72 182 181 158 113 102 140 130 100 79 69 95 167 205 203 204 204 210 219 217 218 224 225 229 230 226 221 215 209 209 206 199 194 191 184 150 73 21 23 55 39 31 185 148 99 62 53 31 116 194 190 164 111 75 98 124 112 75 56 53 87 144 178 181 194 205 211 208 216 221 221 223 222 213 203 207 208 209 208 204 198 195 181 157 88 28 14 35 60 40 164 140 104 70 53 35 149 210 213 202 132 37 61 127 160 143 89 57 66 95 126 152 186 211 215 202 201 207 210 205 206 206 205 215 218 213 210 205 204 196 186 160 97 31 19 10 46 70 155 142 103 71 38 46 184 231 235 230 193 105 57 43 52 92 118 93 70 81 92 133 182 210 212 196 177 186 193 204 208 219 223 223 225 222 218 212 203 196 185 161 109 37 15 24 9 61 156 140 105 69 34 62 217 244 245 239 226 184 95 82 20 2 58 101 83 77 84 143 202 210 203 185 150 146 143 147 152 155 165 154 155 174 181 199 210 197 180 165 124 43 16 27 20 11 153 137 114 69 32 82 238 247 249 245 233 219 146 99 110 104 126 121 67 101 109 175 224 220 208 192 146 98 79 64 52 49 60 63 75 102 126 151 174 187 181 164 137 49 12 21 34 13 146 134 119 68 27 98 248 245 250 249 245 238 214 148 108 130 155 171 171 164 165 212 239 226 215 196 132 76 60 51 47 50 59 80 108 121 141 156 163 153 170 171 140 49 3 20 30 25 140 137 104 65 22 96 251 243 249 251 247 243 240 228 199 178 180 186 190 189 205 244 246 231 214 187 137 104 66 50 55 74 113 118 124 151 145 147 165 163 155 170 137 42 0 19 26 31 151 113 80 71 12 91 245 238 244 248 247 242 239 234 229 222 214 216 218 222 239 249 242 232 211 191 179 166 91 32 35 19 63 119 104 95 129 117 122 156 166 163 137 43 0 17 24 33 129 78 81 60 6 83 234 228 236 238 243 244 245 244 242 241 243 245 245 244 247 245 238 216 202 200 202 185 161 114 66 18 0 12 51 48 57 107 106 142 162 166 148 46 0 12 19 27 113 81 77 48 11 66 226 221 234 239 242 245 247 249 248 250 252 253 247 248 248 243 232 203 202 207 213 207 190 157 131 114 73 63 52 20 17 59 126 143 166 177 158 47 0 5 14 16 112 89 72 48 2 70 222 213 226 235 241 243 244 245 246 247 247 245 246 250 248 242 227 202 202 208 215 219 207 194 152 110 88 79 66 74 102 117 147 171 187 187 161 46 0 1 10 11 109 84 71 31 0 98 224 203 215 228 235 237 241 238 237 234 220 236 251 254 246 244 222 202 202 206 215 223 218 211 209 185 150 143 151 172 195 198 196 200 199 190 159 42 0 0 6 16 93 78 78 27 3 131 224 203 211 220 228 231 233 238 234 206 217 250 253 251 247 242 217 200 196 202 211 224 227 218 213 223 223 217 212 207 207 209 208 206 202 190 152 37 0 2 1 19 88 104 85 28 11 156 219 204 218 229 239 245 249 250 248 232 241 249 252 248 244 241 213 193 191 194 208 219 226 229 223 220 224 224 220 215 213 213 210 208 201 184 135 26 1 3 0 14 107 132 71 41 57 182 233 234 246 252 253 251 248 246 242 233 222 236 241 244 249 232 204 202 192 184 204 216 222 228 227 224 224 225 220 217 217 214 211 205 195 171 95 19 4 4 0 6 145 148 168 225 247 248 250 250 244 241 246 246 244 239 229 216 204 167 180 216 221 215 200 210 200 185 201 212 220 225 225 224 219 217 218 215 214 211 207 200 184 133 59 21 3 4 0 4 165 227 255 255 249 238 231 232 235 236 244 239 229 209 191 199 197 136 122 154 147 153 181 197 193 191 196 210 217 219 221 218 213 209 210 211 209 207 196 189 155 83 33 18 11 0 0 4 232 255 252 251 249 244 241 239 235 235 220 196 182 172 180 156 166 174 94 102 101 66 86 140 191 207 196 205 214 213 213 211 208 205 202 201 200 191 180 164 113 71 73 46 1 0 1 2 255 254 255 254 255 255 255 250 236 227 219 203 181 175 127 142 171 201 111 80 130 144 125 159 217 221 202 201 208 207 206 202 197 195 190 189 183 174 158 129 100 95 93 28 0 3 0 5 254 255 255 255 255 251 252 245 223 213 225 233 236 230 209 197 195 198 166 139 186 197 209 217 223 225 212 202 203 199 196 191 183 180 177 170 163 153 132 121 117 123 82 8 1 2 0 14 255 255 255 255 252 247 245 234 216 218 220 219 222 227 234 235 228 218 185 193 206 206 214 217 220 224 214 204 201 195 187 179 174 166 158 149 145 132 137 132 143 124 38 0 5 0 0 29 255 255 255 254 251 248 243 230 220 219 218 216 223 224 224 226 224 227 211 204 227 223 214 212 215 218 211 204 198 191 180 169 163 153 142 139 133 140 139 49 58 25 0 4 8 0 5 45 255 255 254 250 245 243 240 238 234 230 224 209 205 206 205 208 210 216 214 120 146 211 220 213 210 208 207 200 190 184 172 160 150 140 136 138 140 156 93 0 0 0 3 12 14 1 10 53 255 254 250 249 247 244 244 246 249 250 244 227 217 212 205 197 177 184 205 103 37 91 154 202 209 200 197 192 184 175 161 149 143 142 143 149 151 145 38 2 9 3 16 23 27 2 11 65 253 249 248 248 248 245 245 249 250 251 251 230 223 232 231 233 227 216 215 149 48 20 35 90 155 184 187 180 180 169 156 151 153 155 153 155 156 104 14 10 9 15 33 36 44 2 18 76 247 247 250 250 249 249 253 252 250 252 244 224 218 225 224 226 228 228 231 230 187 153 110 81 94 139 170 177 173 169 160 164 165 163 161 155 145 48 14 23 22 27 43 46 60 11 28 87 247 252 251 252 254 253 251 250 250 246 236 225 216 217 224 226 230 226 218 217 174 161 185 186 179 160 160 175 178 173 168 169 171 167 158 151 96 19 22 46 44 43 64 54 75 25 38 97 252 252 252 254 252 247 245 247 247 248 249 246 243 221 200 193 189 189 198 205 170 154 168 173 178 174 165 167 168 163 165 170 171 163 150 120 51 25 41 66 58 63 77 55 76 45 53 106 253 252 252 246 242 240 243 244 245 246 249 248 250 243 229 229 231 233 234 237 232 204 170 175 175 174 165 154 152 157 165 167 163 142 120 96 45 31 47 70 68 77 94 63 64 70 66 111 252 248 241 236 238 242 246 248 250 250 249 247 247 240 228 230 234 237 234 233 241 239 187 158 163 161 155 146 151 161 166 157 131 117 116 98 40 44 62 79 70 113 112 74 46 81 82 117 246 237 235 240 246 249 252 254 253 251 249 249 249 235 215 219 224 222 222 219 220 224 188 154 157 153 151 154 163 161 142 117 118 133 125 98 45 55 73 83 87 143 113 73 49 70 110 131 241 238 244 248 251 253 253 252 251 248 240 233 226 217 210 219 219 215 216 216 210 200 173 164 159 153 156 160 148 122 101 119 149 134 126 96 48 52 75 103 119 157 107 73 61 53 114 137 241 245 250 252 253 253 250 246 242 237 229 221 213 206 210 203 186 172 145 130 152 161 167 166 152 143 132 114 95 94 121 148 144 129 134 95 46 49 97 114 147 151 104 82 72 57 101 146 246 250 252 252 250 247 242 238 232 227 220 212 204 199 179 173 167 105 65 63 90 134 161 134 112 92 78 81 99 124 147 151 133 134 134 84 42 73 112 122 155 131 105 96 88 78 105 162 250 251 250 248 244 240 237 230 225 220 215 207 199 167 108 151 122 88 71 84 120 127 105 76 71 78 90 106 123 146 155 148 130 141 119 69 54 89 104 138 152 122 114 101 97 88 110 152\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "jr4PNulULpFz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b21337b5"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixel_string = self.data.iloc[idx]['pixels']\n",
        "        label = int(self.data.iloc[idx]['emotion'])\n",
        "\n",
        "        pixels = np.array([int(p) for p in pixel_string.split()], dtype=np.uint8).reshape(48, 48)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(pixels)\n",
        "        else:\n",
        "            image = torch.tensor(pixels, dtype=torch.float32).unsqueeze(0) / 255.0\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84bdada",
        "outputId": "f6621863-5d26-46e1-f13e-89c5eb4b8c6d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['emotion'], random_state=42)\n",
        "\n",
        "train_dataset = FERDataset(train_df, transform=transform)\n",
        "val_dataset = FERDataset(val_df, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"Training DataLoader created with\", len(train_loader), \"batches.\")\n",
        "print(\"Validation DataLoader created with\", len(val_loader), \"batches.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataLoader created with 359 batches.\n",
            "Validation DataLoader created with 90 batches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "sA85-cj2P-dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class ToPILImageAndAugment:\n",
        "    def __init__(self, augmentations):\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __call__(self, x):\n",
        "        img = Image.fromarray(x, mode='L')\n",
        "        return self.augmentations(img)\n",
        "\n",
        "train_augmentations = T.Compose([\n",
        "    T.RandomResizedCrop(48, scale=(0.9, 1.1), ratio=(0.9, 1.1)),\n",
        "    T.RandomRotation(20),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomApply([T.GaussianBlur(kernel_size=3)], p=0.1),  # slight blur noise\n",
        "    T.RandomApply([T.RandomAffine(degrees=0, translate=(0.1, 0.1))], p=0.2),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset_t = FERDataset(train_df, transform=ToPILImageAndAugment(train_augmentations))\n",
        "train_loader_t = DataLoader(train_dataset_t, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "valid_transforms = T.Compose([\n",
        "    T.Resize(48),           # resize to 48x48 (same as training crop size)\n",
        "    T.CenterCrop(48),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "val_dataset_t = FERDataset(val_df, transform=ToPILImageAndAugment(valid_transforms))\n",
        "val_loader_t = DataLoader(val_dataset_t, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "YHOZyJBrQAsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wandb"
      ],
      "metadata": {
        "id": "5c5bC97_QNeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "3PsqwFEUcHFa",
        "outputId": "88b381ad-a8b3-4aad-cfc9-ad78d5f6e857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhorzholianimate\u001b[0m (\u001b[33mzhorzholianimate-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Function"
      ],
      "metadata": {
        "id": "0KVFgOdNJGZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, device, train_loader, val_loader,\n",
        "                num_epochs=10, scheduler=None, project_name=\"fer-cnn\", group_name=\"\", run_name=None):\n",
        "    import wandb\n",
        "    wandb.init(project=project_name, name=run_name, group=group_name)\n",
        "\n",
        "    wandb.config.update({\n",
        "        \"epochs\": num_epochs,\n",
        "        \"batch_size\": train_loader.batch_size,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"architecture\": str(model),\n",
        "    })\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct = 0.0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_acc = correct / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_val_loss, correct_val = 0.0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item() * labels.size(0)\n",
        "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        val_acc = correct_val / len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc,\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "        })\n",
        "\n",
        "        if scheduler:\n",
        "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                scheduler.step(val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "-HiKir9jJJNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40806855"
      },
      "source": [
        "# SqueezeNet\n",
        "\n",
        "We will be using the SqueezeNet architecture on our dataset. SqueezeNet is a convolutional neural network architecture designed for efficient deep learning, introduced in the paper [\"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\"](https://arxiv.org/abs/1602.07360).\n",
        "\n",
        "The architecture we will use is essentially the same as the PyTorch implementation found [here](https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/squeezenet.py#L37), but it has been modified to handle grayscale images as input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/Facial Expression Recognition Challenge\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from models.squeezenet import squeezenet1_1\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = squeezenet1_1(pretrained=False, num_classes=7)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)\n",
        "\n",
        "train_model(model, criterion, optimizer, device, train_loader_t, val_loader_t,\n",
        "            num_epochs=20, scheduler=scheduler, group_name='SqueezeNet', run_name=\"squeezenet_1x48x48_03\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "kXHweVmEN99e",
        "outputId": "0ee8b80b-0070-4ae4-b21a-aae69b692119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250608_122400-r5oixqml</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/r5oixqml' target=\"_blank\">squeezenet_1x48x48_03</a></strong> to <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/r5oixqml' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/r5oixqml</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: 1.8484, Train Acc: 0.2468 | Val Loss: 1.8298, Val Acc: 0.2513\n",
            "Epoch 2/20 | Train Loss: 1.8268, Train Acc: 0.2532 | Val Loss: 1.8193, Val Acc: 0.2579\n",
            "Epoch 3/20 | Train Loss: 1.7597, Train Acc: 0.2884 | Val Loss: 1.6698, Val Acc: 0.3238\n",
            "Epoch 4/20 | Train Loss: 1.6821, Train Acc: 0.3227 | Val Loss: 1.6351, Val Acc: 0.3551\n",
            "Epoch 5/20 | Train Loss: 1.6349, Train Acc: 0.3522 | Val Loss: 1.6321, Val Acc: 0.3483\n",
            "Epoch 6/20 | Train Loss: 1.6026, Train Acc: 0.3650 | Val Loss: 1.5202, Val Acc: 0.3990\n",
            "Epoch 7/20 | Train Loss: 1.5692, Train Acc: 0.3831 | Val Loss: 1.5311, Val Acc: 0.4049\n",
            "Epoch 8/20 | Train Loss: 1.5463, Train Acc: 0.3972 | Val Loss: 1.5212, Val Acc: 0.4117\n",
            "Epoch 9/20 | Train Loss: 1.5212, Train Acc: 0.4066 | Val Loss: 1.4414, Val Acc: 0.4357\n",
            "Epoch 10/20 | Train Loss: 1.5030, Train Acc: 0.4180 | Val Loss: 1.4205, Val Acc: 0.4485\n",
            "Epoch 11/20 | Train Loss: 1.4781, Train Acc: 0.4269 | Val Loss: 1.4107, Val Acc: 0.4572\n",
            "Epoch 12/20 | Train Loss: 1.4632, Train Acc: 0.4347 | Val Loss: 1.4173, Val Acc: 0.4512\n",
            "Epoch 13/20 | Train Loss: 1.4533, Train Acc: 0.4424 | Val Loss: 1.4053, Val Acc: 0.4641\n",
            "Epoch 14/20 | Train Loss: 1.4355, Train Acc: 0.4504 | Val Loss: 1.3622, Val Acc: 0.4753\n",
            "Epoch 15/20 | Train Loss: 1.4188, Train Acc: 0.4557 | Val Loss: 1.3820, Val Acc: 0.4742\n",
            "Epoch 16/20 | Train Loss: 1.4146, Train Acc: 0.4576 | Val Loss: 1.3615, Val Acc: 0.4842\n",
            "Epoch 17/20 | Train Loss: 1.4009, Train Acc: 0.4640 | Val Loss: 1.3478, Val Acc: 0.4944\n",
            "Epoch 18/20 | Train Loss: 1.3937, Train Acc: 0.4686 | Val Loss: 1.3320, Val Acc: 0.4943\n",
            "Epoch 19/20 | Train Loss: 1.3846, Train Acc: 0.4700 | Val Loss: 1.3210, Val Acc: 0.4944\n",
            "Epoch 20/20 | Train Loss: 1.3782, Train Acc: 0.4734 | Val Loss: 1.3173, Val Acc: 0.4962\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▅▅▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>██▇▆▅▄▄▄▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▃▄▄▅▅▆▆▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>██▆▅▅▄▄▄▃▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0.47337</td></tr><tr><td>train_loss</td><td>1.3782</td></tr><tr><td>val_accuracy</td><td>0.49617</td></tr><tr><td>val_loss</td><td>1.31731</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">squeezenet_1x48x48_03</strong> at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/r5oixqml' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/r5oixqml</a><br> View project at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250608_122400-r5oixqml/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45249024"
      },
      "source": [
        "# ResNet\n",
        "\n",
        "Based on the training of simpler models, it appears that they may not be sufficient for this task. As you add more layers to a plain neural network, performance often gets worse, not better. This isn't just due to overfitting—it’s an optimization issue: deeper networks are harder to train because gradients can vanish or explode, and useful signals can get lost. To address this, we will use the ResNet architecture, introduced in the paper [\"Deep Residual Learning for Image Recognition\"](https://arxiv.org/abs/1512.03385), which utilizes techniques called residual connections. These connections help mitigate the training difficulties of deep networks and improve performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "def get_resnet18_for_grayscale(num_classes, pretrained=True):\n",
        "    weights = ResNet18_Weights.DEFAULT if pretrained else None\n",
        "    model = resnet18(weights=weights)\n",
        "    original_conv = model.conv1\n",
        "    model.conv1 = nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=original_conv.out_channels,\n",
        "        kernel_size=original_conv.kernel_size,\n",
        "        stride=original_conv.stride,\n",
        "        padding=original_conv.padding,\n",
        "        bias=original_conv.bias is not None,\n",
        "    )\n",
        "    if pretrained:\n",
        "        with torch.no_grad():\n",
        "            model.conv1.weight = nn.Parameter(original_conv.weight.sum(dim=1, keepdim=True))\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7jNH2KJrWcXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I will train with the pre-trained model with augmented data, and then without augmentation."
      ],
      "metadata": {
        "id": "wdrldWFnatSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = 7\n",
        "\n",
        "model = get_resnet18_for_grayscale(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "train_model(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10,\n",
        "    scheduler=scheduler,\n",
        "    project_name=\"fer-cnn\",\n",
        "    group_name=\"resnet-gray\",\n",
        "    run_name=\"resnet18-gray\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "klRevNNzWe5_",
        "outputId": "28dea370-f85e-4528-ca5e-ab7e96c91102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250608_114744-83bru66i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/83bru66i' target=\"_blank\">resnet18-gray</a></strong> to <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/83bru66i' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/83bru66i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.4775, Train Acc: 0.4418 | Val Loss: 1.2416, Val Acc: 0.5270\n",
            "Epoch 2/10 | Train Loss: 1.0068, Train Acc: 0.6295 | Val Loss: 1.1985, Val Acc: 0.5632\n",
            "Epoch 3/10 | Train Loss: 0.6564, Train Acc: 0.7650 | Val Loss: 1.2750, Val Acc: 0.5730\n",
            "Epoch 4/10 | Train Loss: 0.3576, Train Acc: 0.8818 | Val Loss: 1.4644, Val Acc: 0.5709\n",
            "Epoch 5/10 | Train Loss: 0.2132, Train Acc: 0.9335 | Val Loss: 1.6660, Val Acc: 0.5834\n",
            "Epoch 6/10 | Train Loss: 0.0998, Train Acc: 0.9754 | Val Loss: 1.5679, Val Acc: 0.5925\n",
            "Epoch 7/10 | Train Loss: 0.0529, Train Acc: 0.9910 | Val Loss: 1.5824, Val Acc: 0.5970\n",
            "Epoch 8/10 | Train Loss: 0.0374, Train Acc: 0.9943 | Val Loss: 1.6135, Val Acc: 0.5967\n",
            "Epoch 9/10 | Train Loss: 0.0301, Train Acc: 0.9955 | Val Loss: 1.6446, Val Acc: 0.5975\n",
            "Epoch 10/10 | Train Loss: 0.0252, Train Acc: 0.9962 | Val Loss: 1.6572, Val Acc: 0.6021\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>█████▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▇▇█████</td></tr><tr><td>train_loss</td><td>█▆▄▃▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▅▆▇█▇██</td></tr><tr><td>val_loss</td><td>▂▁▂▅█▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>train_accuracy</td><td>0.99621</td></tr><tr><td>train_loss</td><td>0.02519</td></tr><tr><td>val_accuracy</td><td>0.60206</td></tr><tr><td>val_loss</td><td>1.65715</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-gray</strong> at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/83bru66i' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/83bru66i</a><br> View project at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250608_114744-83bru66i/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = 7\n",
        "\n",
        "model = get_resnet18_for_grayscale(num_classes=num_classes, pretrained=True).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "train_model(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader_t,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10,\n",
        "    scheduler=scheduler,\n",
        "    project_name=\"fer-cnn\",\n",
        "    group_name=\"resnet-gray\",\n",
        "    run_name=\"resnet18-gray-01\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "PSXRxqOSY4kW",
        "outputId": "988bcaeb-8e33-422d-db76-4164d291e95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250608_115533-ew8rxpjh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/ew8rxpjh' target=\"_blank\">resnet18-gray-01</a></strong> to <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/ew8rxpjh' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/ew8rxpjh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.6011, Train Acc: 0.3816 | Val Loss: 1.4090, Val Acc: 0.4765\n",
            "Epoch 2/10 | Train Loss: 1.3444, Train Acc: 0.4867 | Val Loss: 1.2665, Val Acc: 0.5174\n",
            "Epoch 3/10 | Train Loss: 1.2392, Train Acc: 0.5295 | Val Loss: 1.1739, Val Acc: 0.5566\n",
            "Epoch 4/10 | Train Loss: 1.1680, Train Acc: 0.5557 | Val Loss: 1.1306, Val Acc: 0.5735\n",
            "Epoch 5/10 | Train Loss: 1.1229, Train Acc: 0.5774 | Val Loss: 1.1012, Val Acc: 0.5817\n",
            "Epoch 6/10 | Train Loss: 1.0370, Train Acc: 0.6085 | Val Loss: 1.0680, Val Acc: 0.5909\n",
            "Epoch 7/10 | Train Loss: 1.0103, Train Acc: 0.6169 | Val Loss: 1.0654, Val Acc: 0.5947\n",
            "Epoch 8/10 | Train Loss: 0.9900, Train Acc: 0.6262 | Val Loss: 1.0698, Val Acc: 0.5920\n",
            "Epoch 9/10 | Train Loss: 0.9790, Train Acc: 0.6330 | Val Loss: 1.0608, Val Acc: 0.6005\n",
            "Epoch 10/10 | Train Loss: 0.9630, Train Acc: 0.6380 | Val Loss: 1.0645, Val Acc: 0.5968\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>█████▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>train_accuracy</td><td>0.638</td></tr><tr><td>train_loss</td><td>0.96296</td></tr><tr><td>val_accuracy</td><td>0.59683</td></tr><tr><td>val_loss</td><td>1.06446</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-gray-01</strong> at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/ew8rxpjh' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/ew8rxpjh</a><br> View project at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250608_115533-ew8rxpjh/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now without pretrained model."
      ],
      "metadata": {
        "id": "Ml01H_1XazHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = 7\n",
        "\n",
        "model = get_resnet18_for_grayscale(num_classes=num_classes, pretrained=False).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "train_model(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10,\n",
        "    scheduler=scheduler,\n",
        "    project_name=\"fer-cnn\",\n",
        "    group_name=\"resnet-gray\",\n",
        "    run_name=\"resnet18-gray-03\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "v89vFsduabQg",
        "outputId": "f4de92bf-b770-4c98-b107-ae24509e93c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250608_121001-d9y3x390</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/d9y3x390' target=\"_blank\">resnet18-gray-03</a></strong> to <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/d9y3x390' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/d9y3x390</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.6143, Train Acc: 0.3654 | Val Loss: 1.5182, Val Acc: 0.4040\n",
            "Epoch 2/10 | Train Loss: 1.2925, Train Acc: 0.5148 | Val Loss: 1.4901, Val Acc: 0.4411\n",
            "Epoch 3/10 | Train Loss: 0.9384, Train Acc: 0.6569 | Val Loss: 1.5551, Val Acc: 0.4657\n",
            "Epoch 4/10 | Train Loss: 0.5454, Train Acc: 0.8098 | Val Loss: 1.8553, Val Acc: 0.4601\n",
            "Epoch 5/10 | Train Loss: 0.2866, Train Acc: 0.9040 | Val Loss: 2.2236, Val Acc: 0.4556\n",
            "Epoch 6/10 | Train Loss: 0.1061, Train Acc: 0.9729 | Val Loss: 2.1647, Val Acc: 0.4648\n",
            "Epoch 7/10 | Train Loss: 0.0483, Train Acc: 0.9925 | Val Loss: 2.1912, Val Acc: 0.4657\n",
            "Epoch 8/10 | Train Loss: 0.0337, Train Acc: 0.9953 | Val Loss: 2.2585, Val Acc: 0.4687\n",
            "Epoch 9/10 | Train Loss: 0.0265, Train Acc: 0.9959 | Val Loss: 2.2933, Val Acc: 0.4683\n",
            "Epoch 10/10 | Train Loss: 0.0234, Train Acc: 0.9960 | Val Loss: 2.3453, Val Acc: 0.4646\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>█████▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▆▇█████</td></tr><tr><td>train_loss</td><td>█▇▅▃▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅█▇▇█████</td></tr><tr><td>val_loss</td><td>▁▁▂▄▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>train_accuracy</td><td>0.99595</td></tr><tr><td>train_loss</td><td>0.02342</td></tr><tr><td>val_accuracy</td><td>0.46465</td></tr><tr><td>val_loss</td><td>2.34529</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-gray-03</strong> at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/d9y3x390' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/d9y3x390</a><br> View project at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250608_121001-d9y3x390/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = 7\n",
        "\n",
        "model = get_resnet18_for_grayscale(num_classes=num_classes, pretrained=False).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "train_model(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader_t,\n",
        "    val_loader=val_loader_t,\n",
        "    num_epochs=10,\n",
        "    scheduler=scheduler,\n",
        "    project_name=\"fer-cnn\",\n",
        "    group_name=\"resnet-gray\",\n",
        "    run_name=\"resnet18-gray-04\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "1RgOCMtDdn4Y",
        "outputId": "f8ac68b4-1d35-455e-ceee-498ad01a8271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250608_121708-8d92ccxb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/8d92ccxb' target=\"_blank\">resnet18-gray-04</a></strong> to <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/8d92ccxb' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/8d92ccxb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.7207, Train Acc: 0.3086 | Val Loss: 1.5863, Val Acc: 0.3772\n",
            "Epoch 2/10 | Train Loss: 1.5967, Train Acc: 0.3728 | Val Loss: 1.5043, Val Acc: 0.4235\n",
            "Epoch 3/10 | Train Loss: 1.5303, Train Acc: 0.4080 | Val Loss: 1.4266, Val Acc: 0.4559\n",
            "Epoch 4/10 | Train Loss: 1.4751, Train Acc: 0.4284 | Val Loss: 1.3878, Val Acc: 0.4687\n",
            "Epoch 5/10 | Train Loss: 1.4298, Train Acc: 0.4480 | Val Loss: 1.3320, Val Acc: 0.4915\n",
            "Epoch 6/10 | Train Loss: 1.3719, Train Acc: 0.4731 | Val Loss: 1.3052, Val Acc: 0.5063\n",
            "Epoch 7/10 | Train Loss: 1.3555, Train Acc: 0.4785 | Val Loss: 1.2928, Val Acc: 0.5115\n",
            "Epoch 8/10 | Train Loss: 1.3469, Train Acc: 0.4836 | Val Loss: 1.2871, Val Acc: 0.5153\n",
            "Epoch 9/10 | Train Loss: 1.3375, Train Acc: 0.4890 | Val Loss: 1.2838, Val Acc: 0.5167\n",
            "Epoch 10/10 | Train Loss: 1.3206, Train Acc: 0.4927 | Val Loss: 1.2788, Val Acc: 0.5193\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>█████▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇▇████</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>train_accuracy</td><td>0.49266</td></tr><tr><td>train_loss</td><td>1.32059</td></tr><tr><td>val_accuracy</td><td>0.51933</td></tr><tr><td>val_loss</td><td>1.27875</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-gray-04</strong> at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/8d92ccxb' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn/runs/8d92ccxb</a><br> View project at: <a href='https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn' target=\"_blank\">https://wandb.ai/zhorzholianimate-free-university-of-tbilisi-/fer-cnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250608_121708-8d92ccxb/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}